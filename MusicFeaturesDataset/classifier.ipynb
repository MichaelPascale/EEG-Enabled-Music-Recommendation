{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   track_id  genre  mfcc_kurtosis1  mfcc_kurtosis2  mfcc_kurtosis3  \\\n0        10     10        5.076893        1.161854        2.095651   \n1       237      4        0.050286        1.453483       -0.065162   \n2       238      4        0.150942        0.836303        0.519024   \n3       246     12       10.034222        2.345979        0.350005   \n4       253     12        5.879405        0.155489       -0.686100   \n\n   mfcc_kurtosis4  mfcc_kurtosis5  mfcc_kurtosis6  mfcc_kurtosis7  \\\n0        1.372743       -0.203574       -0.345354       -0.529139   \n1       -0.053700       -0.925963       -0.696073       -0.278583   \n2        0.299592       -0.134583       -0.500563       -0.409461   \n3        2.705259        2.145471        0.118018       -0.003343   \n4       -0.062248        0.648070        0.433033        0.262114   \n\n   mfcc_kurtosis8  ...  mfcc_std11  mfcc_std12  mfcc_std13  mfcc_std14  \\\n0        0.561974  ...    8.289734    7.985110    7.075400    6.972649   \n1        0.123087  ...   10.396290   12.253343    9.079613    7.972744   \n2        0.004446  ...   10.203614   10.019124    9.046419    9.445981   \n3        0.109671  ...    5.802963    6.720185    7.771977    6.778006   \n4        0.264016  ...    9.581501    7.915710    7.448792    7.308044   \n\n   mfcc_std15  mfcc_std16  mfcc_std17  mfcc_std18  mfcc_std19  mfcc_std20  \n0    7.071393    7.270959    7.051070    6.928591    6.430473    6.186294  \n1    7.650872    7.508337    7.851484    7.980201    7.641377    7.672569  \n2    8.800344    8.697709    8.398916    8.786415   10.356650   11.473572  \n3    7.835801    6.235694    6.747839    5.855201    6.131346    5.518766  \n4    7.393054    6.894248    9.178191    8.979139    8.622712    8.231733  \n\n[5 rows x 142 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>track_id</th>\n      <th>genre</th>\n      <th>mfcc_kurtosis1</th>\n      <th>mfcc_kurtosis2</th>\n      <th>mfcc_kurtosis3</th>\n      <th>mfcc_kurtosis4</th>\n      <th>mfcc_kurtosis5</th>\n      <th>mfcc_kurtosis6</th>\n      <th>mfcc_kurtosis7</th>\n      <th>mfcc_kurtosis8</th>\n      <th>...</th>\n      <th>mfcc_std11</th>\n      <th>mfcc_std12</th>\n      <th>mfcc_std13</th>\n      <th>mfcc_std14</th>\n      <th>mfcc_std15</th>\n      <th>mfcc_std16</th>\n      <th>mfcc_std17</th>\n      <th>mfcc_std18</th>\n      <th>mfcc_std19</th>\n      <th>mfcc_std20</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>10</td>\n      <td>5.076893</td>\n      <td>1.161854</td>\n      <td>2.095651</td>\n      <td>1.372743</td>\n      <td>-0.203574</td>\n      <td>-0.345354</td>\n      <td>-0.529139</td>\n      <td>0.561974</td>\n      <td>...</td>\n      <td>8.289734</td>\n      <td>7.985110</td>\n      <td>7.075400</td>\n      <td>6.972649</td>\n      <td>7.071393</td>\n      <td>7.270959</td>\n      <td>7.051070</td>\n      <td>6.928591</td>\n      <td>6.430473</td>\n      <td>6.186294</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>237</td>\n      <td>4</td>\n      <td>0.050286</td>\n      <td>1.453483</td>\n      <td>-0.065162</td>\n      <td>-0.053700</td>\n      <td>-0.925963</td>\n      <td>-0.696073</td>\n      <td>-0.278583</td>\n      <td>0.123087</td>\n      <td>...</td>\n      <td>10.396290</td>\n      <td>12.253343</td>\n      <td>9.079613</td>\n      <td>7.972744</td>\n      <td>7.650872</td>\n      <td>7.508337</td>\n      <td>7.851484</td>\n      <td>7.980201</td>\n      <td>7.641377</td>\n      <td>7.672569</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>238</td>\n      <td>4</td>\n      <td>0.150942</td>\n      <td>0.836303</td>\n      <td>0.519024</td>\n      <td>0.299592</td>\n      <td>-0.134583</td>\n      <td>-0.500563</td>\n      <td>-0.409461</td>\n      <td>0.004446</td>\n      <td>...</td>\n      <td>10.203614</td>\n      <td>10.019124</td>\n      <td>9.046419</td>\n      <td>9.445981</td>\n      <td>8.800344</td>\n      <td>8.697709</td>\n      <td>8.398916</td>\n      <td>8.786415</td>\n      <td>10.356650</td>\n      <td>11.473572</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>246</td>\n      <td>12</td>\n      <td>10.034222</td>\n      <td>2.345979</td>\n      <td>0.350005</td>\n      <td>2.705259</td>\n      <td>2.145471</td>\n      <td>0.118018</td>\n      <td>-0.003343</td>\n      <td>0.109671</td>\n      <td>...</td>\n      <td>5.802963</td>\n      <td>6.720185</td>\n      <td>7.771977</td>\n      <td>6.778006</td>\n      <td>7.835801</td>\n      <td>6.235694</td>\n      <td>6.747839</td>\n      <td>5.855201</td>\n      <td>6.131346</td>\n      <td>5.518766</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>253</td>\n      <td>12</td>\n      <td>5.879405</td>\n      <td>0.155489</td>\n      <td>-0.686100</td>\n      <td>-0.062248</td>\n      <td>0.648070</td>\n      <td>0.433033</td>\n      <td>0.262114</td>\n      <td>0.264016</td>\n      <td>...</td>\n      <td>9.581501</td>\n      <td>7.915710</td>\n      <td>7.448792</td>\n      <td>7.308044</td>\n      <td>7.393054</td>\n      <td>6.894248</td>\n      <td>9.178191</td>\n      <td>8.979139</td>\n      <td>8.622712</td>\n      <td>8.231733</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 142 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import pandas\n",
    "input_data = pandas.read_csv(\"output.csv\")\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1972,)"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "mapper = {2: 0, 3: 1, 4: 2, 5: 3, 8:4,9:5,10:6,12:7,14:8,15:9, 17:10, 21:11,38:12, 1235:13 }\n",
    "labels = input_data['genre'].replace(mapper)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1972, 14)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "labels = keras.utils.to_categorical(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1972, 140)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "data = input_data.drop(columns=['genre', 'track_id'])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# Feature Layer\n",
    "model.add(keras.layers.Dense(140, input_dim=data.shape[1], activation='relu'))\n",
    "model.add(keras.layers.Dense(200, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "# Classification Layer\n",
    "model.add(keras.layers.Dense(labels.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/1577 [==============================] - 0s 35us/sample - loss: 0.8765 - accuracy: 0.7070 - val_loss: 1.4684 - val_accuracy: 0.6481\nEpoch 18/150\n1577/1577 [==============================] - 0s 34us/sample - loss: 0.7643 - accuracy: 0.7432 - val_loss: 1.8690 - val_accuracy: 0.5646\nEpoch 19/150\n1577/1577 [==============================] - 0s 38us/sample - loss: 0.7566 - accuracy: 0.7540 - val_loss: 1.4682 - val_accuracy: 0.6557\nEpoch 20/150\n1577/1577 [==============================] - 0s 35us/sample - loss: 0.7486 - accuracy: 0.7514 - val_loss: 1.4249 - val_accuracy: 0.6937\nEpoch 21/150\n1577/1577 [==============================] - 0s 38us/sample - loss: 0.7193 - accuracy: 0.7698 - val_loss: 1.5962 - val_accuracy: 0.6456\nEpoch 22/150\n1577/1577 [==============================] - 0s 35us/sample - loss: 0.6847 - accuracy: 0.7552 - val_loss: 1.5471 - val_accuracy: 0.6937\nEpoch 23/150\n1577/1577 [==============================] - 0s 34us/sample - loss: 0.7167 - accuracy: 0.7578 - val_loss: 1.8209 - val_accuracy: 0.5620\nEpoch 24/150\n1577/1577 [==============================] - 0s 34us/sample - loss: 0.7092 - accuracy: 0.7584 - val_loss: 1.8608 - val_accuracy: 0.6278\nEpoch 25/150\n1577/1577 [==============================] - 0s 36us/sample - loss: 0.7371 - accuracy: 0.7476 - val_loss: 1.5278 - val_accuracy: 0.6937\nEpoch 26/150\n1577/1577 [==============================] - 0s 34us/sample - loss: 0.5913 - accuracy: 0.8003 - val_loss: 1.4424 - val_accuracy: 0.6810\nEpoch 27/150\n1577/1577 [==============================] - 0s 34us/sample - loss: 0.5996 - accuracy: 0.7863 - val_loss: 1.8652 - val_accuracy: 0.5823\nEpoch 28/150\n1577/1577 [==============================] - 0s 34us/sample - loss: 0.5915 - accuracy: 0.7926 - val_loss: 1.4884 - val_accuracy: 0.6785\nEpoch 29/150\n1577/1577 [==============================] - 0s 36us/sample - loss: 0.5033 - accuracy: 0.8358 - val_loss: 1.7763 - val_accuracy: 0.5722\nEpoch 30/150\n1577/1577 [==============================] - 0s 33us/sample - loss: 0.6085 - accuracy: 0.7990 - val_loss: 1.5294 - val_accuracy: 0.6810\nEpoch 31/150\n1577/1577 [==============================] - 0s 35us/sample - loss: 0.5930 - accuracy: 0.7907 - val_loss: 1.7896 - val_accuracy: 0.6253\nEpoch 32/150\n1577/1577 [==============================] - 0s 38us/sample - loss: 0.5661 - accuracy: 0.8072 - val_loss: 1.7366 - val_accuracy: 0.6278\nEpoch 33/150\n1577/1577 [==============================] - 0s 36us/sample - loss: 0.6227 - accuracy: 0.7838 - val_loss: 1.6486 - val_accuracy: 0.6380\nEpoch 34/150\n1577/1577 [==============================] - 0s 36us/sample - loss: 0.5658 - accuracy: 0.8199 - val_loss: 1.8468 - val_accuracy: 0.6557\nEpoch 35/150\n1577/1577 [==============================] - 0s 36us/sample - loss: 0.4733 - accuracy: 0.8459 - val_loss: 1.9953 - val_accuracy: 0.6127\nEpoch 36/150\n1577/1577 [==============================] - 0s 36us/sample - loss: 0.4641 - accuracy: 0.8377 - val_loss: 1.6222 - val_accuracy: 0.6861\nEpoch 37/150\n1577/1577 [==============================] - 0s 37us/sample - loss: 0.4687 - accuracy: 0.8523 - val_loss: 1.7620 - val_accuracy: 0.6633\nEpoch 38/150\n1577/1577 [==============================] - 0s 37us/sample - loss: 0.4712 - accuracy: 0.8383 - val_loss: 1.5926 - val_accuracy: 0.6633\nEpoch 39/150\n1577/1577 [==============================] - 0s 36us/sample - loss: 0.4375 - accuracy: 0.8503 - val_loss: 1.8229 - val_accuracy: 0.6557\nEpoch 40/150\n1577/1577 [==============================] - 0s 34us/sample - loss: 0.4477 - accuracy: 0.8567 - val_loss: 1.8871 - val_accuracy: 0.6582\nEpoch 41/150\n1577/1577 [==============================] - 0s 37us/sample - loss: 0.4387 - accuracy: 0.8535 - val_loss: 1.9938 - val_accuracy: 0.6481\nEpoch 42/150\n1577/1577 [==============================] - 0s 35us/sample - loss: 0.4218 - accuracy: 0.8567 - val_loss: 1.9512 - val_accuracy: 0.6582\nEpoch 43/150\n1577/1577 [==============================] - 0s 39us/sample - loss: 0.4406 - accuracy: 0.8510 - val_loss: 1.8192 - val_accuracy: 0.6430\nEpoch 44/150\n1577/1577 [==============================] - 0s 39us/sample - loss: 0.4506 - accuracy: 0.8402 - val_loss: 1.5147 - val_accuracy: 0.6658\nEpoch 45/150\n1577/1577 [==============================] - 0s 38us/sample - loss: 0.4486 - accuracy: 0.8453 - val_loss: 2.2679 - val_accuracy: 0.5418\nEpoch 46/150\n1577/1577 [==============================] - 0s 52us/sample - loss: 0.3672 - accuracy: 0.8713 - val_loss: 2.6566 - val_accuracy: 0.4532\nEpoch 47/150\n1577/1577 [==============================] - 0s 36us/sample - loss: 0.3929 - accuracy: 0.8637 - val_loss: 1.9580 - val_accuracy: 0.6278\nEpoch 48/150\n1577/1577 [==============================] - 0s 38us/sample - loss: 0.4341 - accuracy: 0.8497 - val_loss: 2.5821 - val_accuracy: 0.4886\nEpoch 49/150\n1577/1577 [==============================] - 0s 35us/sample - loss: 0.4035 - accuracy: 0.8586 - val_loss: 1.8782 - val_accuracy: 0.6380\nEpoch 50/150\n1577/1577 [==============================] - 0s 34us/sample - loss: 0.3267 - accuracy: 0.8935 - val_loss: 1.8908 - val_accuracy: 0.6354\nEpoch 51/150\n1577/1577 [==============================] - 0s 36us/sample - loss: 0.2944 - accuracy: 0.9112 - val_loss: 1.8309 - val_accuracy: 0.6608\nEpoch 52/150\n1577/1577 [==============================] - 0s 35us/sample - loss: 0.2831 - accuracy: 0.9125 - val_loss: 1.8497 - val_accuracy: 0.6430\nEpoch 53/150\n1577/1577 [==============================] - 0s 37us/sample - loss: 0.2802 - accuracy: 0.9087 - val_loss: 1.9410 - val_accuracy: 0.6430\nEpoch 54/150\n1577/1577 [==============================] - 0s 35us/sample - loss: 0.2970 - accuracy: 0.8998 - val_loss: 1.9427 - val_accuracy: 0.6329\nEpoch 55/150\n1577/1577 [==============================] - 0s 36us/sample - loss: 0.2665 - accuracy: 0.9195 - val_loss: 1.8111 - val_accuracy: 0.6759\nEpoch 56/150\n1577/1577 [==============================] - 0s 37us/sample - loss: 0.2623 - accuracy: 0.9163 - val_loss: 2.0591 - val_accuracy: 0.6532\nEpoch 57/150\n1577/1577 [==============================] - 0s 38us/sample - loss: 0.2830 - accuracy: 0.8998 - val_loss: 1.9078 - val_accuracy: 0.6608\nEpoch 58/150\n1577/1577 [==============================] - 0s 37us/sample - loss: 0.3881 - accuracy: 0.8630 - val_loss: 2.2078 - val_accuracy: 0.6380\nEpoch 59/150\n1577/1577 [==============================] - 0s 36us/sample - loss: 0.3465 - accuracy: 0.8852 - val_loss: 2.3531 - val_accuracy: 0.6000\nEpoch 60/150\n1577/1577 [==============================] - 0s 36us/sample - loss: 0.2719 - accuracy: 0.9081 - val_loss: 2.3938 - val_accuracy: 0.5949\nEpoch 61/150\n1577/1577 [==============================] - 0s 36us/sample - loss: 0.2763 - accuracy: 0.9068 - val_loss: 1.9927 - val_accuracy: 0.6506\nEpoch 62/150\n1577/1577 [==============================] - 0s 33us/sample - loss: 0.2213 - accuracy: 0.9328 - val_loss: 2.0259 - val_accuracy: 0.6532\nEpoch 63/150\n1577/1577 [==============================] - 0s 40us/sample - loss: 0.2045 - accuracy: 0.9366 - val_loss: 2.2605 - val_accuracy: 0.6127\nEpoch 64/150\n1577/1577 [==============================] - 0s 41us/sample - loss: 0.1943 - accuracy: 0.9448 - val_loss: 2.0400 - val_accuracy: 0.6430\nEpoch 65/150\n1577/1577 [==============================] - 0s 41us/sample - loss: 0.1788 - accuracy: 0.9499 - val_loss: 2.2746 - val_accuracy: 0.6127\nEpoch 66/150\n1577/1577 [==============================] - 0s 40us/sample - loss: 0.2003 - accuracy: 0.9448 - val_loss: 2.0800 - val_accuracy: 0.6582\nEpoch 67/150\n1577/1577 [==============================] - 0s 40us/sample - loss: 0.1891 - accuracy: 0.9442 - val_loss: 2.1491 - val_accuracy: 0.6304\nEpoch 68/150\n1577/1577 [==============================] - 0s 40us/sample - loss: 0.2102 - accuracy: 0.9366 - val_loss: 2.3237 - val_accuracy: 0.6405\nEpoch 69/150\n1577/1577 [==============================] - 0s 38us/sample - loss: 0.2321 - accuracy: 0.9277 - val_loss: 2.4782 - val_accuracy: 0.5823\nEpoch 70/150\n1577/1577 [==============================] - 0s 36us/sample - loss: 0.1811 - accuracy: 0.9499 - val_loss: 2.1605 - val_accuracy: 0.6608\nEpoch 71/150\n1577/1577 [==============================] - 0s 36us/sample - loss: 0.1734 - accuracy: 0.9461 - val_loss: 2.4638 - val_accuracy: 0.6329\nEpoch 72/150\n1577/1577 [==============================] - 0s 34us/sample - loss: 0.1778 - accuracy: 0.9505 - val_loss: 2.2059 - val_accuracy: 0.6633\nEpoch 73/150\n1577/1577 [==============================] - 0s 38us/sample - loss: 0.1366 - accuracy: 0.9607 - val_loss: 2.5367 - val_accuracy: 0.5975\nEpoch 74/150\n1577/1577 [==============================] - 0s 36us/sample - loss: 0.1290 - accuracy: 0.9632 - val_loss: 2.2990 - val_accuracy: 0.6506\nEpoch 75/150\n1577/1577 [==============================] - 0s 34us/sample - loss: 0.1225 - accuracy: 0.9772 - val_loss: 2.2391 - val_accuracy: 0.6810\nEpoch 76/150\n1577/1577 [==============================] - 0s 34us/sample - loss: 0.1259 - accuracy: 0.9715 - val_loss: 2.3079 - val_accuracy: 0.6506\nEpoch 77/150\n1577/1577 [==============================] - 0s 39us/sample - loss: 0.1209 - accuracy: 0.9734 - val_loss: 2.1282 - val_accuracy: 0.6785\nEpoch 78/150\n1577/1577 [==============================] - 0s 37us/sample - loss: 0.1299 - accuracy: 0.9651 - val_loss: 2.2335 - val_accuracy: 0.6684\nEpoch 79/150\n1577/1577 [==============================] - 0s 36us/sample - loss: 0.1262 - accuracy: 0.9746 - val_loss: 2.3352 - val_accuracy: 0.6658\nEpoch 80/150\n1577/1577 [==============================] - 0s 37us/sample - loss: 0.1337 - accuracy: 0.9664 - val_loss: 2.5588 - val_accuracy: 0.6456\nEpoch 81/150\n1577/1577 [==============================] - 0s 36us/sample - loss: 0.1199 - accuracy: 0.9696 - val_loss: 2.5822 - val_accuracy: 0.6076\nEpoch 82/150\n1577/1577 [==============================] - 0s 41us/sample - loss: 0.0975 - accuracy: 0.9803 - val_loss: 2.2435 - val_accuracy: 0.6658\nEpoch 83/150\n1577/1577 [==============================] - 0s 39us/sample - loss: 0.0883 - accuracy: 0.9924 - val_loss: 2.4455 - val_accuracy: 0.6380\nEpoch 84/150\n1577/1577 [==============================] - 0s 41us/sample - loss: 0.0831 - accuracy: 0.9880 - val_loss: 2.3626 - val_accuracy: 0.6734\nEpoch 85/150\n1577/1577 [==============================] - 0s 37us/sample - loss: 0.0840 - accuracy: 0.9899 - val_loss: 2.6016 - val_accuracy: 0.6152\nEpoch 86/150\n1577/1577 [==============================] - 0s 38us/sample - loss: 0.0790 - accuracy: 0.9892 - val_loss: 2.7613 - val_accuracy: 0.6329\nEpoch 87/150\n1577/1577 [==============================] - 0s 48us/sample - loss: 0.0778 - accuracy: 0.9886 - val_loss: 2.5243 - val_accuracy: 0.6456\nEpoch 88/150\n1577/1577 [==============================] - 0s 39us/sample - loss: 0.0767 - accuracy: 0.9867 - val_loss: 2.4250 - val_accuracy: 0.6532\nEpoch 89/150\n1577/1577 [==============================] - 0s 37us/sample - loss: 0.0779 - accuracy: 0.9880 - val_loss: 2.4527 - val_accuracy: 0.6380\nEpoch 90/150\n1577/1577 [==============================] - 0s 37us/sample - loss: 0.0842 - accuracy: 0.9835 - val_loss: 2.9063 - val_accuracy: 0.6127\nEpoch 91/150\n1577/1577 [==============================] - 0s 38us/sample - loss: 0.0972 - accuracy: 0.9772 - val_loss: 2.8577 - val_accuracy: 0.6101\nEpoch 92/150\n1577/1577 [==============================] - 0s 38us/sample - loss: 0.0761 - accuracy: 0.9854 - val_loss: 2.6214 - val_accuracy: 0.6304\nEpoch 93/150\n1577/1577 [==============================] - 0s 41us/sample - loss: 0.0767 - accuracy: 0.9854 - val_loss: 2.5187 - val_accuracy: 0.6481\nEpoch 94/150\n1577/1577 [==============================] - 0s 38us/sample - loss: 0.0699 - accuracy: 0.9899 - val_loss: 2.5735 - val_accuracy: 0.6532\nEpoch 95/150\n1577/1577 [==============================] - 0s 38us/sample - loss: 0.0681 - accuracy: 0.9892 - val_loss: 2.6762 - val_accuracy: 0.6430\nEpoch 96/150\n1577/1577 [==============================] - 0s 35us/sample - loss: 0.0611 - accuracy: 0.9924 - val_loss: 2.6328 - val_accuracy: 0.6481\nEpoch 97/150\n1577/1577 [==============================] - 0s 40us/sample - loss: 0.0553 - accuracy: 0.9949 - val_loss: 2.6084 - val_accuracy: 0.6430\nEpoch 98/150\n1577/1577 [==============================] - 0s 36us/sample - loss: 0.0526 - accuracy: 0.9949 - val_loss: 2.7211 - val_accuracy: 0.6380\nEpoch 99/150\n1577/1577 [==============================] - 0s 35us/sample - loss: 0.0451 - accuracy: 0.9975 - val_loss: 2.8917 - val_accuracy: 0.6304\nEpoch 100/150\n1577/1577 [==============================] - 0s 37us/sample - loss: 0.0432 - accuracy: 0.9975 - val_loss: 2.6864 - val_accuracy: 0.6557\nEpoch 101/150\n1577/1577 [==============================] - 0s 44us/sample - loss: 0.0384 - accuracy: 0.9994 - val_loss: 2.7375 - val_accuracy: 0.6430\nEpoch 102/150\n1577/1577 [==============================] - 0s 43us/sample - loss: 0.0394 - accuracy: 0.9968 - val_loss: 2.8955 - val_accuracy: 0.6203\nEpoch 103/150\n1577/1577 [==============================] - 0s 44us/sample - loss: 0.0464 - accuracy: 0.9937 - val_loss: 2.7489 - val_accuracy: 0.6481\nEpoch 104/150\n1577/1577 [==============================] - 0s 41us/sample - loss: 0.0497 - accuracy: 0.9899 - val_loss: 2.6835 - val_accuracy: 0.6354\nEpoch 105/150\n1577/1577 [==============================] - 0s 43us/sample - loss: 0.0498 - accuracy: 0.9943 - val_loss: 2.6924 - val_accuracy: 0.6481\nEpoch 106/150\n1577/1577 [==============================] - 0s 41us/sample - loss: 0.0440 - accuracy: 0.9956 - val_loss: 2.7503 - val_accuracy: 0.6608\nEpoch 107/150\n1577/1577 [==============================] - 0s 49us/sample - loss: 0.0438 - accuracy: 0.9956 - val_loss: 2.7313 - val_accuracy: 0.6405\nEpoch 108/150\n1577/1577 [==============================] - 0s 38us/sample - loss: 0.0389 - accuracy: 0.9987 - val_loss: 2.9365 - val_accuracy: 0.6405\nEpoch 109/150\n1577/1577 [==============================] - 0s 35us/sample - loss: 0.0326 - accuracy: 0.9994 - val_loss: 2.9709 - val_accuracy: 0.6304\nEpoch 110/150\n1577/1577 [==============================] - 0s 38us/sample - loss: 0.0295 - accuracy: 1.0000 - val_loss: 2.8891 - val_accuracy: 0.6329\nEpoch 111/150\n1577/1577 [==============================] - 0s 37us/sample - loss: 0.0275 - accuracy: 0.9994 - val_loss: 2.9049 - val_accuracy: 0.6430\nEpoch 112/150\n1577/1577 [==============================] - 0s 38us/sample - loss: 0.0262 - accuracy: 1.0000 - val_loss: 2.8360 - val_accuracy: 0.6506\nEpoch 113/150\n1577/1577 [==============================] - 0s 35us/sample - loss: 0.0290 - accuracy: 0.9994 - val_loss: 2.9275 - val_accuracy: 0.6405\nEpoch 114/150\n1577/1577 [==============================] - 0s 34us/sample - loss: 0.0276 - accuracy: 0.9994 - val_loss: 3.0110 - val_accuracy: 0.6354\nEpoch 115/150\n1577/1577 [==============================] - 0s 34us/sample - loss: 0.0311 - accuracy: 0.9975 - val_loss: 2.8743 - val_accuracy: 0.6456\nEpoch 116/150\n1577/1577 [==============================] - 0s 37us/sample - loss: 0.0267 - accuracy: 0.9994 - val_loss: 2.7171 - val_accuracy: 0.6684\nEpoch 117/150\n1577/1577 [==============================] - 0s 46us/sample - loss: 0.0245 - accuracy: 0.9994 - val_loss: 2.8569 - val_accuracy: 0.6456\nEpoch 118/150\n1577/1577 [==============================] - 0s 40us/sample - loss: 0.0241 - accuracy: 1.0000 - val_loss: 2.8962 - val_accuracy: 0.6608\nEpoch 119/150\n1577/1577 [==============================] - 0s 40us/sample - loss: 0.0252 - accuracy: 1.0000 - val_loss: 2.7809 - val_accuracy: 0.6608\nEpoch 120/150\n1577/1577 [==============================] - 0s 37us/sample - loss: 0.0278 - accuracy: 0.9981 - val_loss: 3.0054 - val_accuracy: 0.6430\nEpoch 121/150\n1577/1577 [==============================] - 0s 35us/sample - loss: 0.0225 - accuracy: 1.0000 - val_loss: 2.9461 - val_accuracy: 0.6582\nEpoch 122/150\n1577/1577 [==============================] - 0s 37us/sample - loss: 0.0218 - accuracy: 1.0000 - val_loss: 3.0943 - val_accuracy: 0.6380\nEpoch 123/150\n1577/1577 [==============================] - 0s 35us/sample - loss: 0.0213 - accuracy: 1.0000 - val_loss: 2.9470 - val_accuracy: 0.6506\nEpoch 124/150\n1577/1577 [==============================] - 0s 38us/sample - loss: 0.0219 - accuracy: 0.9994 - val_loss: 2.9532 - val_accuracy: 0.6532\nEpoch 125/150\n1577/1577 [==============================] - 0s 40us/sample - loss: 0.0187 - accuracy: 1.0000 - val_loss: 2.9662 - val_accuracy: 0.6456\nEpoch 126/150\n1577/1577 [==============================] - 0s 37us/sample - loss: 0.0185 - accuracy: 1.0000 - val_loss: 2.9120 - val_accuracy: 0.6481\nEpoch 127/150\n1577/1577 [==============================] - 0s 39us/sample - loss: 0.0184 - accuracy: 1.0000 - val_loss: 3.0481 - val_accuracy: 0.6506\nEpoch 128/150\n1577/1577 [==============================] - 0s 40us/sample - loss: 0.0166 - accuracy: 1.0000 - val_loss: 3.1133 - val_accuracy: 0.6456\nEpoch 129/150\n1577/1577 [==============================] - 0s 43us/sample - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.9943 - val_accuracy: 0.6430\nEpoch 130/150\n1577/1577 [==============================] - 0s 40us/sample - loss: 0.0153 - accuracy: 1.0000 - val_loss: 3.1216 - val_accuracy: 0.6481\nEpoch 131/150\n1577/1577 [==============================] - 0s 42us/sample - loss: 0.0150 - accuracy: 1.0000 - val_loss: 3.0525 - val_accuracy: 0.6557\nEpoch 132/150\n1577/1577 [==============================] - 0s 41us/sample - loss: 0.0141 - accuracy: 1.0000 - val_loss: 3.0402 - val_accuracy: 0.6506\nEpoch 133/150\n1577/1577 [==============================] - 0s 38us/sample - loss: 0.0146 - accuracy: 1.0000 - val_loss: 3.0989 - val_accuracy: 0.6430\nEpoch 134/150\n1577/1577 [==============================] - 0s 42us/sample - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.9698 - val_accuracy: 0.6633\nEpoch 135/150\n1577/1577 [==============================] - 0s 41us/sample - loss: 0.0155 - accuracy: 1.0000 - val_loss: 3.2610 - val_accuracy: 0.6405\nEpoch 136/150\n1577/1577 [==============================] - 0s 43us/sample - loss: 0.0261 - accuracy: 0.9943 - val_loss: 3.0339 - val_accuracy: 0.6430\nEpoch 137/150\n1577/1577 [==============================] - 0s 41us/sample - loss: 0.0483 - accuracy: 0.9873 - val_loss: 3.0461 - val_accuracy: 0.6532\nEpoch 138/150\n1577/1577 [==============================] - 0s 40us/sample - loss: 0.0372 - accuracy: 0.9956 - val_loss: 3.4400 - val_accuracy: 0.6177\nEpoch 139/150\n1577/1577 [==============================] - 0s 38us/sample - loss: 0.0274 - accuracy: 0.9975 - val_loss: 3.1303 - val_accuracy: 0.6253\nEpoch 140/150\n1577/1577 [==============================] - 0s 42us/sample - loss: 0.0375 - accuracy: 0.9937 - val_loss: 3.0457 - val_accuracy: 0.6481\nEpoch 141/150\n1577/1577 [==============================] - 0s 38us/sample - loss: 0.0261 - accuracy: 0.9987 - val_loss: 2.9458 - val_accuracy: 0.6506\nEpoch 142/150\n1577/1577 [==============================] - 0s 39us/sample - loss: 0.0193 - accuracy: 0.9987 - val_loss: 3.1578 - val_accuracy: 0.6405\nEpoch 143/150\n1577/1577 [==============================] - 0s 41us/sample - loss: 0.0154 - accuracy: 1.0000 - val_loss: 3.1511 - val_accuracy: 0.6532\nEpoch 144/150\n1577/1577 [==============================] - 0s 39us/sample - loss: 0.0135 - accuracy: 1.0000 - val_loss: 3.2200 - val_accuracy: 0.6582\nEpoch 145/150\n1577/1577 [==============================] - 0s 40us/sample - loss: 0.0121 - accuracy: 1.0000 - val_loss: 3.1514 - val_accuracy: 0.6557\nEpoch 146/150\n1577/1577 [==============================] - 0s 41us/sample - loss: 0.0114 - accuracy: 1.0000 - val_loss: 3.1605 - val_accuracy: 0.6456\nEpoch 147/150\n1577/1577 [==============================] - 0s 44us/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 3.2208 - val_accuracy: 0.6608\nEpoch 148/150\n1577/1577 [==============================] - 0s 40us/sample - loss: 0.0100 - accuracy: 1.0000 - val_loss: 3.2313 - val_accuracy: 0.6481\nEpoch 149/150\n1577/1577 [==============================] - 0s 43us/sample - loss: 0.0088 - accuracy: 1.0000 - val_loss: 3.2002 - val_accuracy: 0.6608\nEpoch 150/150\n1577/1577 [==============================] - 0s 39us/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 3.1645 - val_accuracy: 0.6557\n"
    }
   ],
   "source": [
    "history = model.fit(data, labels, epochs=150, batch_size=140, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Assets written to: tfmodel/assets\n"
    }
   ],
   "source": [
    "model.save('tfmodel')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bit533d17ae73a14cb1a6145e231e915fc2",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}